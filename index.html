<!DOCTYPE HTML>
<html>
	<head>
		<title>Dynamics-Guided Diffusion Model for Sensor-less Robot Manipulator Design</title>
		<meta charset="utf-8" />
		 <meta name="viewport" content="width=1000">
		<link rel="stylesheet" href="assets/css/main.css" />

		<meta property="og:url"           content="https://dgdmcorl.github.io" />
	    <meta property="og:type"          content="website" />
	    <meta property="og:title"         content="Dynamics-Guided Diffusion Model for Sensor-less Robot Manipulator Design" />
	    <meta property="og:description"   content="We present Dynamics-Guided Diffusion Model, a data-driven framework for generating manipulator geometry designs for a given manipulation task. Instead of training different design models for each task, our approach employs a learned dynamics network shared across tasks. For a new manipulation task, we first decompose it into a collection of individual motion targets which we call target interaction profile, where each individual motion can be modeled by the shared dynamics network. The design objective constructed from the target and predicted interaction profiles provides a gradient to guide the refinement of finger geometry for the task. This refinement process is executed as a classifier-guided diffusion process, where the design objective acts as the classifier guidance. We evaluate our framework on various manipulation tasks, under the sensor-less setting using only an open-loop parallel jaw motion. Our generated designs outperform optimization-based and unguided diffusion baselines relatively by 31.5% and 45.3% on average manipulation success rate. With the ability to generate a design within 0.8 seconds, our framework could facilitate rapid design iteration and enhance the adoption of data-driven approaches for robotic mechanism design." />
	
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	</head>
	<body id="top">


		<!-- Main -->
			<div id="main" style="padding-bottom:1em; padding-top: 5em; width: 60em; max-width: 70em; margin-left: auto; margin-right: auto;">
					<section id="four">
                        <h1 style="text-align: center; margin-bottom: 1em; color: #4e79a7; font-size: 200%">Dynamics-Guided Diffusion Model <br>for Sensor-less Robot Manipulator Design</h1>

						<div class="row 50% uniform" style="width: 100%; color: black;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 25%">
								Shift Down
							</div>

							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 25%">
								Shift Right
							</div>

							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 25%">
								Rotate Counterclockwise
							</div>

							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 25%">
								Pose Convergence
							</div>
						</div>

						<div class="box alt" style="margin-bottom: 0em;">
							<div class="row 50% uniform" style="width: 100%;">
								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/T_down.mp4" type="video/mp4"> 
									</video>
								</div>

								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/T_right.mp4" type="video/mp4"> 
									</video>
								</div>

								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/T_counter.mp4" type="video/mp4"> 
									</video>
								</div>

								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/T_cvgr.mp4" type="video/mp4"> 
									</video>
								</div>
							</div>

							<div class="row 50% uniform" style="width: 100%">
								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/chair_down.mp4" type="video/mp4"> 
									</video>
								</div>

								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/chair_right.mp4" type="video/mp4"> 
									</video>
								</div>

								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/chair_counter.mp4" type="video/mp4"> 
									</video>
								</div>

								<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
									<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
										<source src="videos/chair_cvgr.mp4" type="video/mp4"> 
									</video>
								</div>
							</div>
						</div>


						<div class="row 50% uniform" style="width: 100%; color: black;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%">
								<h3>Task-specific Designs without Task-specific Training</h3>
							</div>
						</div>
						<br>

						<p style="color: black;">We present Dynamics-Guided Diffusion Model (DGDM), a data-driven framework for generating task-specific manipulator designs without task-specific training. Given object shapes and task specifications, DGDM generates sensor-less manipulator designs that can blindly manipulate objects towards desired motions and poses using an open-loop parallel motion. This framework 1) flexibly represents manipulation tasks as interaction profiles, 2) represents the design space using a geometric diffusion model, and 3) efficiently searches this design space using the gradients provided by a dynamics network trained without any task information. We evaluate DGDM on various manipulation tasks ranging from shifting/rotating objects to converging objects to a specific pose. Our generated designs outperform optimization-based and unguided diffusion baselines relatively by 31.5% and 45.3% on average success rate. With the ability to generate a new design within 0.8s, DGDM facilitates rapid design iteration and enhances the adoption of data-driven approaches for robot mechanism design.
						</p>
						

						<div class="row">
							<div class="12u$ 12u$(xsmall)" style="text-align: center;">
								<h3>Technical Summary Video (with audio)</h3>
								<iframe width="840" height="473" src="https://www.youtube.com/embed/cjrHlNdLWCc?si=I9o7wxs6GjWgRhUM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
							</div>
						</div>
					
						<hr>
						<h3>Qualitative Results</h3>
						<b>Pose Convergence</b>
						<br>
						The goal of pose convergence is to design fingers that always reorient a target object to a specified orientation (in the manipulator frame) when closing the gripper in parallel.
						As you can imagine, this manipulator can be quite useful in industrial settings such as assembly lines. When objects are fed in with different poses we can automatically align them to the same pose, and move objects to any particular configuration combined with a global transformation of the gripper.
						<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
								<span class="image fit">
									<video autoplay loop muted playsinline style="width: 90%;">
										<source src="videos/belt2.mp4" type="video/mp4">	
									</video>
								</span>
							</div>
						</div>

						<br>
						More examples of pose convergence manipulators in the real world:
						<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/car-cvgr_VFrZyhiR.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/heart-cvgr-1_KoSa0LEa.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/cup-cvgr-1.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/basket-cvgr_awWJ7hfl.mp4" type="video/mp4"> 
								</video>
							</div>
						</div>

						<br>
						<div id="cvgr_compare">
							<b>Comparison with related work on convergence task</b>
							<br>
							We added a comparison to <a href="https://arxiv.org/abs/1909.03985">certified grasping</a> for the convergence task.
							This method achieves convergence through trajectory optimization instead of manipulator design optimization. However, with a more complex system (two 7 DoF arms and two parallel jaw grippers), their system can only achieve a much smaller convergence range (45 degrees, 1.4 cm) than ours (140 degrees, 8 cm) on the T object. This method can only work for this one convergence task on polygon object shapes, while our method could be used for different objectives and a wider range of objects.
							<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
								<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
									<span class="image mid">
										<img src="images/t-cvgr-1.png" alt=""/>
									</span>
								</div>
							</div>
							<br>
						</div>

						<div id="progress">
							<b>Task progress over action horizon</b>
							<br>
							We plot the progress of convergence over 40 open-close actions with manipulators generated by baselines and DGDM.
							The Unguided baseline converges the slowest, taking more than 30 steps. The Opt. baseline exhibits an unstable dip at the start and only achieves consistent alignment with the target orientation after 30 steps.
							Manipulators generated by DGDM not only have larger convergence ranges but also converge faster (with 10 steps) than the baselines.
							<div class="row 50% uniform" style="width: 100%; margin-top: 0.em;">
								<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
									<span class="image small">
										<img src="images/progress.png" alt=""/>
									</span>
								</div>
							</div>
							<br>
						</div>

						<b>Rotate</b>
						<div class="row 50% uniform" style="width: 100%; color: black;">
							<div class="2u" style="font-size: 1.0em; line-height: 1.5em; text-align: center; width: 50%">
								Counterclockwise
							</div>

							<div class="2u" style="font-size: 1.0em; line-height: 1.5em; text-align: center; width: 50%">
								Clockwise
							</div>
						</div>

						<div class="row 50% uniform" style="width: 100%;">
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/heart-counter_rJ0znRMm.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/basket-counter_Pq2zWpV2.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/t-clock-real_hp17m6e1.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/plane-clock-1_j2xhPu8y.mp4" type="video/mp4"> 
								</video>
							</div>
						</div>

						<br>
						<b>Shift Up/Down</b>
						<div class="row 50% uniform" style="width: 100%; color: black;">
							<div class="2u" style="font-size: 1.0em; line-height: 1.5em; text-align: center; width: 50%">
								Up
							</div>

							<div class="2u" style="font-size: 1.0em; line-height: 1.5em; text-align: center; width: 50%">
								Down
							</div>
						</div>

						<div class="row 50% uniform" style="width: 100%;">
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/t-up_yPnRiMw7.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/chair-up_0uphthiB.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/heart-down_I9VBjQxg.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/car-down_LMML6ORm.mp4" type="video/mp4"> 
								</video>
							</div>
						</div>

						<br>
						<b>Shift Left/Right</b>
						<div class="row 50% uniform" style="width: 100%; color: black;">
							<div class="2u" style="font-size: 1.0em; line-height: 1.5em; text-align: center; width: 50%">
								Left
							</div>

							<div class="2u" style="font-size: 1.0em; line-height: 1.5em; text-align: center; width: 50%">
								Right
							</div>
						</div>

						<div class="row 50% uniform" style="width: 100%;">
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/t-left_xYITwqkf.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/car-left_hJ3Z6bbO.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/heart-right_1CgyJbAu.mp4" type="video/mp4"> 
								</video>
							</div>
						
							<div class="2u video-container" style="position: relative; overflow: hidden; width: 25%;">
								<video autoplay loop muted playsinline style="width: 200px; height: 280px; object-fit: cover;">
									<source src="videos/basket-right.mp4" type="video/mp4"> 
								</video>
							</div>
						</div>

						<h3 style="margin-top: 0.8em;">Multi-object Results</h3>
						Our framework also allows designing manipulators for a set of objects to achieve a task.
						<br>
						<b>Rotate Clockwise</b>
						<div class="row 50% uniform" style="width: 100%;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 33.3%;">
								<span class="image fit">
									<video autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
										<source src="videos/multi_clock/T.mp4" type="video/mp4">	
									</video>
								</span>
							</div>

							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 33.3%;">
								<span class="image fit">
									<video autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
										<source src="videos/multi_clock/car.mp4" type="video/mp4">
									</video>
								</span>
							</div>

							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 33.3%;">
								<span class="image fit">
									<video autoplay loop muted playsinline style="width: 100%; margin-right: 5%;">
										<source src="videos/multi_clock/house.mp4" type="video/mp4">	
									</video>
								</span>
							</div>
						</div>

						<!-- <hr>
						<h3>Quantitative Results</h3>
 -->

						<hr>
						<h3 id="interaction_profile">Details on Interaction Profile</h3>
						<b>Interaction Profile</b>
						<br>
						The interaction profile between a manipulator and an object is defined as the distribution of the delta pose change of the object caused by the manipulator-object interaction over all possible initial poses of the object. 
						Here, the manipulators-object interaction is a simple parallel closing action, and the object pose is represented as 2D translation and rotation.   
						For example, in the figure below, when the object's initial pose is \( (\theta,x,y) \), its delta pose after the interaction is \( (\Delta\theta,\Delta x,\Delta y) \), which provide one data point on the interaction profile. Then, by uniformly sampling all initial poses, we obtain the complete interact profile. 
						<br>
						In our implementation, we use simulation to obtain the <b>ground truth interaction profile</b> and train a dynamic network to infer the <b>predicted interaction profile</b> given any manipulator-object pair without simulation. 
						<br>
						<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
								<span class="image fit">
									<img src="images/interaction_profile1.png" alt="" />
								</span>
							</div>
						</div>
						<br>
						<b>Target Interaction Profile</b>
						<br>
						A target interaction profile is defined for a specific task objective. 
						For example, the target interaction profile for the convergence task is shown in the below figure. This interaction profile indicates the object should rotate in a positive direction when its initial orientation is smaller than the convergence rotation; otherwise, it rotates in a negative direction. 
						<br>
						<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
								<span class="image fit">
									<img src="images/target_interaction_profile.png" alt="" />
								</span>
							</div>
						</div>
						<br>
						<b>Target v.s. Predicted Interaction Profile</b>
						<br>
						The difference between the target interaction profile and the predicted interaction profile (inferred by the dynamics network) provides the gradients for the manipulator design (in the below figure). Since the dynamics network is fully differentiable, we can get its gradient with respect to the input manipulator geometry. 
						<br>
						<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
								<span class="image fit">
									<img src="images/gradients.png" alt="" />
								</span>
							</div>
						</div>
						<br>
						<h3 id="list">List of Target Interaction Profile Plots</h3>
						We provide a comprehensive list of task objectives and their corresponding interaction plots. For visualization purposes, we simplify the horizontal axes of interaction profile plots to include only initial orientations \(\theta\).
						<br>
						<div class="row 50% uniform" style="width: 100%; margin-top: 0.2em;">
							<div class="2u" style="font-size: 1em; line-height: 1.5em; text-align: center; width: 100%;">
								<span class="image fit">
									<img src="images/list.png" alt="" />
								</span>
							</div>
					</section>
					
			</div>
			<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
	</body>
</html>